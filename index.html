<html>

<head>
<title>Denis Yarats</title>
<style type="text/css" media="screen">
body {
    position: relative;
    margin: 10px auto;
    width: 840px;
    background: #fff;
}

h1 {
  margin-top: 0;
  margin-bottom: 0;
}

h2 {
  margin-top: 0px;
}

h3 {
  margin-top: 0;
  margin-bottom: 0;
}

body {
  color: #000000;
  background: #FFFFFF;
}

p {
  margin: 5px 0;
  text-align: justify;
}

p.info {
  padding-left: 40px;
}

a:link {
  color: #264889;
}

a:hover, a:active, a:visited:hover {
  color: #4267b2;
  text-decoration: none;
}

a:visited {
  color: #264844;
}

.block {
  margin: 0 0 20px 0;
}

.inner-block {
  padding: 5px;
  float: left;
}

.pub-block {
  margin: 0 0 20px 0;
}

.pub-img {
  position: relative;
  width: 150;
  float: right;
  margin-left: -160;
  border: 1px solid;
}

.pub-img img {
  width: 150px;
  height: auto;
}

.pub-text {
  padding-right: 170px;
  float: right;
}

.clr {
  clear: both;
}
</style>

<link href="http://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic"
rel="stylesheet" type="text/css" />

</head>

<body>

<div class="block">
  <div class="inner-block">
    <img title="Denis Yarats" style="width: 250px; height: auto;" src="images/photo.jpg" />
  </div>
  <div class="inner-block">
    <h1>Denis Yarats</h1>
    <br/>
    <p>I am a Research Engineer at <a href="https://research.fb.com/category/facebook-ai-research-fair" target="_blank">Facebook AI Research (FAIR).</a> </p>
    <p>
      <a href="https://scholar.google.com/citations?user=7kaXqgMAAAAJ&hl=en&pagesize=1000&sortby=pubdate" target="_blank">[Google Scholar]</a>
      <a href="https://github.com/1nadequacy" target="_blank">[GitHub]</a>
      <a href="data/denis_yarats_cv.pdf" target="_blank">[CV]</a>
      [denisyarats at gmail dot com]
    </p>
  </div>
  <div class="clr"></div>
</div>

<div class="block">
  <div class="inner-block">
    <h2>Research</h2>
    <p>My research interest is to develop intelligent agents that can communicate with people and perform useful tasks, with the ultimate ambition to liberate people from the burden of mundane routines. I want to advance the areas of NLP and RL through my research, as they allow the emergence of agents that can evolve over time through their interaction, which is an essential trait of intelligence.</p>
  </div>
  <div class="clr"></div>
</div>

<div class="block">
  <div class="inner-block">
    <h2>Publications</h2>
    <div class="pub-block">
      <div class="pub-img">
        <img title="Deal or No Deal? End-to-End Learning for Negotiation Dialogues" src="images/hiergen.png" />
      </div>
      <div class="pub-text">
        <div class="paper" id="yarats2017hiergen">
          <h3>Hierarchial Text Generation and Planning for Strategic Dialogue.</h3>
          <p><strong>Denis Yarats</strong>*, Mike Lewis*. arXiv 2017. </p>
          <a href="https://arxiv.org/pdf/1712.XXXX.pdf">[PDF]</a>
          <a href="https://arxiv.org/abs/1712.XXXX">[arXiv]</a>
          <br/>
          <p>
          End-to-end models for strategic dialogue are challenging to train, because linguistic and strategic aspects are entangled in latent state vectors. We introduce an approach to generating latent representations of dialogue moves, by inducing sentence representations to maximize the likelihood of subsequent sentences and actions. The effect is to decouple much of the semantics of the utterance from its linguistic realisation. We then use these latent sentence representations for hierarchical language generation, planning and reinforcement learning. Experiments show that using our message representations increases the reward achieved by the model, improves the effectiveness of long-term planning using rollouts, and allows self-play reinforcement learning to improve decision making without diverging from human language.
          Our hierarchical model outperforms previous work both linguistically and strategically.
          </p>
        </div>
      </div>
      <div class="clr"></div>
    </div>

    <div class="pub-block">
      <div class="pub-img">
        <img title="Deal or No Deal? End-to-End Learning for Negotiation Dialogues" src="images/dealornodeal.png" />
      </div>
      <div class="pub-text">
        <div class="paper" id="lewis2017dealornodeal">
          <h3>Deal or No Deal? End-to-End Learning for Negotiation Dialogues.</h3>
          <p>Mike Lewis, <strong>Denis Yarats</strong>, Yann Dauphin, Devi Parikh, Dhruv Batra. EMNLP 2017. </p>
          <a href="https://arxiv.org/pdf/1706.05125.pdf">[PDF]</a>
          <a href="https://arxiv.org/abs/1706.05125">[arXiv]</a>
          <a href="https://github.com/facebookresearch/end-to-end-negotiator">[Code]</a>
          <br/>
          <p>
          Much of human dialogue occurs in semi-cooperative settings, where agents with different goals attempt to agree on common decisions. Negotiations require complex communication and reasoning skills, but success is easy to measure, making this an interesting task for AI. We gather a large dataset of human-human negotiations on a multi-issue bargaining task, where agents who cannot observe each other's reward functions must reach an agreement (or a deal) via natural language dialogue. For the first time, we show it is possible to train end-to-end models for negotiation, which must learn both linguistic and reasoning skills with no annotated dialogue states. We also introduce dialogue rollouts, in which the model plans ahead by simulating possible complete continuations of the conversation, and find that this technique dramatically improves performance. Our code and dataset are publicly available.
          </p>
        </div>
      </div>
      <div class="clr"></div>
    </div>
    <div class="pub-block">
      <div class="pub-img">
        <img title="Convolutional Sequence to Sequence Learning" src="images/convs2s.png" />
      </div>
      <div class="pub-text">
        <div class="paper" id="gehring2017convs2s">
          <h3>Convolutional Sequence to Sequence Learning</h3>
          <p>Jonas Gehring, Michael Auli, David Grangier, <strong>Denis Yarats</strong>, Yann Dauphin. ICML 2017. </p>
          <a href="https://arxiv.org/abs/1705.03122.pdf">[PDF]</a>
          <a href="https://arxiv.org/abs/1705.03122">[arXiv]</a>
          <a href="https://github.com/facebookresearch/fairseq">[Code]</a>
          <p>
          The prevalent approach to sequence to sequence learning maps an input sequence to a variable length output sequence via recurrent neural networks. We introduce an architecture based entirely on convolutional neural networks. Compared to recurrent models, computations over all elements can be fully parallelized during training and optimization is easier since the number of non-linearities is fixed and independent of the input length. Our use of gated linear units eases gradient propagation and we equip each decoder layer with a separate attention module. We outperform the accuracy of the deep LSTM setup of Wu et al. (2016) on both WMT'14 English-German and WMT'14 English-French translation at an order of magnitude faster speed, both on GPU and CPU.
          </p>
        </div>
      </div>
      <div class="clr"></div>
    </div>
  </div>
  <div class="clr"></div>
</div>

<div class="block">
  <div class="inner-block">
    <h2>Talks</h2>
    <div class="pub-block">
      <div class="paper" id="">
        <h3>Convolutional Sequence to Sequence Learning</h3>
        <p>Treehouse Talk at CLMS, University of Washington.</p>
        <a href="data/convs2s_uw.key" target="_blank">[Slides]</a>
      </div>
      <div class="clr"></div>
    </div>
    <div class="pub-block">
      <div class="paper" id="">
        <h3>Convolutional Sequence to Sequence Learning</h3>
        <p>International Conference on Artificial Intelligence (<a href="http://www.aiukraine.com">www.aiukraine.com</a>).</p>
        <a href="data/convs2s_uw.key" target="_blank">[Slides]</a>
      </div>
      <div class="clr"></div>
    </div>
  </div>
  <div class="clr"></div>
</div>

</body>

</html>
